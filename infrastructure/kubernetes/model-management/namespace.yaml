apiVersion: v1
kind: Namespace
metadata:
  name: model-management
  labels:
    app: fineprint-ai
    component: model-management
    environment: production
    cost-center: ai-infrastructure
  annotations:
    scheduler.alpha.kubernetes.io/node-selector: "workload-type=ai"
    cost-optimization: "enabled"
---
apiVersion: v1
kind: ResourceQuota
metadata:
  name: model-management-quota
  namespace: model-management
spec:
  hard:
    requests.cpu: "100"
    requests.memory: "200Gi"
    requests.nvidia.com/gpu: "4"
    persistentvolumeclaims: "10"
    services.loadbalancers: "2"
---
apiVersion: v1
kind: LimitRange
metadata:
  name: model-management-limits
  namespace: model-management
spec:
  limits:
  - max:
      cpu: "16"
      memory: "32Gi"
      nvidia.com/gpu: "1"
    min:
      cpu: "100m"
      memory: "128Mi"
    default:
      cpu: "2"
      memory: "4Gi"
    defaultRequest:
      cpu: "500m"
      memory: "2Gi"
    type: Container
  - max:
      storage: "100Gi"
    min:
      storage: "1Gi"
    type: PersistentVolumeClaim
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: model-management-network-policy
  namespace: model-management
spec:
  podSelector:
    matchLabels:
      app: model-management
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: backend-services
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
    ports:
    - protocol: TCP
      port: 8080
    - protocol: TCP
      port: 11434
  egress:
  - to:
    - namespaceSelector: {}
    ports:
    - protocol: TCP
      port: 443
    - protocol: TCP
      port: 80
    - protocol: TCP
      port: 53
    - protocol: UDP
      port: 53
  - to:
    - podSelector:
        matchLabels:
          app: ollama
    ports:
    - protocol: TCP
      port: 11434