# Enhanced Cache Usage Examples\n\nComprehensive examples demonstrating all features of the enhanced cache system.\n\n## Basic Usage\n\n```typescript\nimport { cache, analysisCache, sessionCache } from '@fineprintai/cache';\n\n// Basic get/set operations\nconst user = { id: 123, name: 'John Doe', email: 'john@example.com' };\nawait cache.set('user:123', user, { ttl: 3600 }); // 1 hour TTL\nconst cachedUser = await cache.get('user:123');\n\n// Check if key exists\nconst exists = await cache.exists('user:123');\nconsole.log('User exists in cache:', exists);\n\n// Delete key\nawait cache.delete('user:123');\n```\n\n## Multi-Level Caching\n\n```typescript\n// The cache automatically uses L1 (memory) and L2 (Redis)\n// L1 hits are sub-millisecond, L2 hits are ~10ms\n\n// First get - L2 hit, promotes to L1\nconst data1 = await cache.get('popular:item'); // ~10ms\n\n// Second get - L1 hit\nconst data2 = await cache.get('popular:item'); // ~0.1ms\n\n// Check cache statistics\nconst stats = cache.getStats();\nconsole.log('L1 hit rate:', stats.l1.hitRate);\nconsole.log('L2 hit rate:', stats.l2.hitRate);\nconsole.log('Overall hit rate:', stats.overall.hitRate);\n```\n\n## Tag-Based Invalidation\n\n```typescript\n// Set data with tags\nawait cache.set('user:123', userData, {\n  ttl: 3600,\n  tags: ['user', 'profile', 'active-users']\n});\n\nawait cache.set('user:456', otherUserData, {\n  ttl: 3600,\n  tags: ['user', 'profile']\n});\n\nawait cache.set('admin:789', adminData, {\n  ttl: 1800,\n  tags: ['admin', 'privileged']\n});\n\n// Invalidate all user profiles\nconst invalidated = await cache.invalidateByTags(['profile']);\nconsole.log(`Invalidated ${invalidated} cache entries`);\n\n// Invalidate by pattern\nconst patternInvalidated = await cache.invalidateByPattern('user:*');\nconsole.log(`Pattern invalidated ${patternInvalidated} entries`);\n```\n\n## Document Analysis Caching\n\n```typescript\nimport { analysisCache } from '@fineprintai/cache';\n\n// Cache analysis result with intelligent TTL\nconst analysisResult = {\n  result: {\n    patterns: ['automatic-renewal', 'data-sharing'],\n    clauses: [\n      { type: 'problematic', text: 'Auto-renewal clause', risk: 0.8 },\n      { type: 'concerning', text: 'Data sharing rights', risk: 0.6 }\n    ]\n  },\n  confidence: 0.95, // High confidence = longer cache TTL\n  processingTime: 2500,\n  modelUsed: 'mistral-7b',\n  patterns: ['automatic-renewal', 'data-sharing'],\n  riskScore: 0.8,\n  createdAt: Date.now()\n};\n\n// Cache with automatic TTL based on confidence\nawait analysisCache.cacheDocumentAnalysis(\n  {\n    documentId: 'doc_123',\n    analysisType: 'full',\n    version: '1.0',\n    model: 'mistral-7b'\n  },\n  analysisResult\n);\n\n// Retrieve with fallback to different versions\nconst cached = await analysisCache.getDocumentAnalysis({\n  documentId: 'doc_123',\n  analysisType: 'full'\n  // Will try: exact match -> without version -> without model\n});\n\n// Invalidate all analyses for a document\nawait analysisCache.invalidateDocumentAnalysis('doc_123');\n```\n\n## Distributed Locking\n\n```typescript\n// Manual lock management\nconst lock = await cache.acquireLock('process:document:123', 30000); // 30s timeout\nif (lock) {\n  try {\n    // Critical section - only one instance can execute this\n    await processExpensiveOperation();\n    await updateDatabase();\n  } finally {\n    await cache.releaseLock(lock);\n  }\n} else {\n  console.log('Could not acquire lock, operation already running');\n}\n\n// Automatic lock management\nawait cache.withLock('process:document:123', async () => {\n  // This code is automatically protected by distributed lock\n  await processExpensiveOperation();\n  await updateDatabase();\n});\n\n// Try lock without waiting\nawait cache.lockManager.tryWithLock('quick:operation', async () => {\n  // Only executes if lock is immediately available\n  await quickOperation();\n});\n```\n\n## Batch Operations\n\n```typescript\n// Batch get - more efficient than individual gets\nconst userIds = ['123', '456', '789'];\nconst userKeys = userIds.map(id => `user:${id}`);\nconst users = await cache.mget(userKeys);\n\n// Process results\nuserKeys.forEach((key, index) => {\n  if (users[index]) {\n    console.log(`Found user: ${key}`, users[index]);\n  } else {\n    console.log(`User not in cache: ${key}`);\n  }\n});\n\n// Batch set\nconst userData = {\n  'user:123': { name: 'Alice', role: 'admin' },\n  'user:456': { name: 'Bob', role: 'user' },\n  'user:789': { name: 'Charlie', role: 'moderator' }\n};\n\nawait cache.mset(userData, {\n  ttl: 3600,\n  tags: ['users', 'profiles']\n});\n\n// Mixed batch operations\nconst operations = [\n  { operation: 'get', key: 'user:123' },\n  { operation: 'set', key: 'user:456', value: updatedUser, options: { ttl: 1800 } },\n  { operation: 'delete', key: 'user:789' }\n];\n\nconst results = await cache.batch(operations);\nresults.forEach((result, index) => {\n  console.log(`Operation ${index}:`, result.success ? 'SUCCESS' : 'FAILED', result.error?.message);\n});\n```\n\n## Cache Warming\n\n```typescript\n// Define data loader function\nconst userLoader = async (key: string): Promise<any> => {\n  const userId = key.split(':')[1];\n  // Simulate database lookup\n  return await database.users.findById(userId);\n};\n\n// Warm cache with frequently accessed users\nconst frequentUserIds = ['123', '456', '789', '101', '102'];\nconst warmedCount = await cache.warmup('user:*', userLoader, {\n  ttl: 7200, // 2 hours\n  priority: 'high',\n  tags: ['users', 'warmup']\n});\n\nconsole.log(`Warmed ${warmedCount} user records`);\n\n// Warm cache using utility function\nimport { CachePerformanceUtils } from '@fineprintai/cache';\n\nconst batchLoader = async (keys: string[]) => {\n  const userIds = keys.map(k => k.split(':')[1]);\n  const users = await database.users.findMany({ id: { in: userIds } });\n  const result: Record<string, any> = {};\n  users.forEach(user => {\n    result[`user:${user.id}`] = user;\n  });\n  return result;\n};\n\nconst warmedUsers = await CachePerformanceUtils.warmupFrequentlyAccessed(\n  cache,\n  batchLoader,\n  frequentUserIds.map(id => `user:${id}`)\n);\n```\n\n## Refresh-Ahead Caching\n\n```typescript\n// Set data with refresh-ahead enabled\nawait cache.set('expensive:computation', computationResult, {\n  ttl: 3600, // 1 hour\n  refreshAhead: true,\n  refreshThreshold: 20 // Refresh when 20% of TTL remains (12 minutes)\n});\n\n// Listen for refresh-ahead events\ncache.on('refreshAhead', async ({ key, options }) => {\n  console.log(`Refresh-ahead triggered for: ${key}`);\n  \n  // Reload data in background\n  try {\n    const freshData = await performExpensiveComputation();\n    await cache.set(key, freshData, options);\n    console.log(`Refreshed cache for: ${key}`);\n  } catch (error) {\n    console.error(`Failed to refresh cache for ${key}:`, error);\n  }\n});\n```\n\n## Compression\n\n```typescript\nimport { compressionPresets } from '@fineprintai/cache';\n\n// Large data that benefits from compression\nconst largeDocument = {\n  id: 'doc_123',\n  content: 'Very large document content...'.repeat(1000),\n  metadata: { /* extensive metadata */ },\n  analysis: { /* detailed analysis results */ }\n};\n\n// Cache with compression\nawait cache.set('document:large', largeDocument, {\n  ttl: 7200,\n  compress: true, // Uses balanced compression by default\n  tags: ['documents', 'large']\n});\n\n// Custom compression configuration\nconst customCache = new EnhancedCacheManager({\n  ...defaultConfig,\n  l2: {\n    ...defaultConfig.l2,\n    compression: compressionPresets.archival // High compression for cold storage\n  }\n});\n\n// Small data - compression disabled automatically\nawait cache.set('small:item', { id: 1, name: 'small' }, {\n  ttl: 3600\n  // Compression is automatically skipped for small values\n});\n```\n\n## Advanced Monitoring\n\n```typescript\nimport { CachePerformanceUtils } from '@fineprintai/cache';\n\n// Monitor cache health\nsetInterval(async () => {\n  await CachePerformanceUtils.monitorHealth(cache);\n}, 60000); // Every minute\n\n// Measure operation performance\nconst { result, duration } = await CachePerformanceUtils.measureOperation(\n  () => performComplexCacheOperation(),\n  'complexOperation'\n);\n\nconsole.log(`Operation completed in ${duration}ms`);\n\n// Get detailed metrics\nconst metrics = cache.getMetrics();\nconsole.log('Top 10 most accessed keys:', metrics.topKeys.slice(0, 10));\nconsole.log('Slow queries:', metrics.slowQueries);\n\n// Export Prometheus metrics\nconst prometheusMetrics = cache.exportPrometheusMetrics();\n// Send to monitoring system...\n\n// Get performance percentiles\nconst percentiles = cache.getPerformancePercentiles();\nconsole.log('Performance percentiles:', {\n  p50: percentiles.p50 + 'ms',\n  p95: percentiles.p95 + 'ms',\n  p99: percentiles.p99 + 'ms'\n});\n```\n\n## Session Caching\n\n```typescript\nimport { sessionCache } from '@fineprintai/cache';\n\n// Session data with appropriate TTL\nconst sessionData = {\n  userId: '123',\n  role: 'admin',\n  permissions: ['read', 'write', 'delete'],\n  loginTime: Date.now(),\n  lastActivity: Date.now()\n};\n\n// Cache session (24 hour TTL by default)\nawait sessionCache.set('session:abc123', sessionData);\n\n// Retrieve and update last activity\nconst session = await sessionCache.get('session:abc123');\nif (session) {\n  session.lastActivity = Date.now();\n  await sessionCache.set('session:abc123', session);\n}\n\n// Clean up expired sessions\nawait sessionCache.invalidateByPattern('session:*');\n```\n\n## API Response Caching\n\n```typescript\nimport { apiCache } from '@fineprintai/cache';\n\n// Cache API responses with short TTL\nconst cacheKey = `api:users:page:${page}:limit:${limit}`;\nlet users = await apiCache.get(cacheKey);\n\nif (!users) {\n  users = await database.users.findMany({ skip: page * limit, take: limit });\n  await apiCache.set(cacheKey, users, {\n    ttl: 300, // 5 minutes\n    tags: ['api', 'users'],\n    refreshAhead: true,\n    refreshThreshold: 25 // Refresh at 25% of TTL\n  });\n}\n\n// Invalidate API cache when data changes\napp.post('/users', async (req, res) => {\n  const newUser = await createUser(req.body);\n  \n  // Invalidate related API cache entries\n  await apiCache.invalidateByTags(['users']);\n  \n  res.json(newUser);\n});\n```\n\n## Rate Limiting Cache\n\n```typescript\nimport { rateLimitCache } from '@fineprintai/cache';\n\n// Implement rate limiting\nasync function checkRateLimit(userId: string, limit: number = 100): Promise<boolean> {\n  const key = `rate:${userId}`;\n  const current = await rateLimitCache.get<number>(key) || 0;\n  \n  if (current >= limit) {\n    return false; // Rate limit exceeded\n  }\n  \n  // Increment counter\n  await rateLimitCache.set(key, current + 1, { ttl: 3600 }); // 1 hour window\n  return true;\n}\n\n// Usage in API endpoint\napp.get('/api/data', async (req, res) => {\n  const userId = req.user.id;\n  \n  if (!await checkRateLimit(userId)) {\n    return res.status(429).json({ error: 'Rate limit exceeded' });\n  }\n  \n  // Process request...\n});\n```\n\n## Error Handling and Circuit Breaker\n\n```typescript\n// The cache includes automatic circuit breaker protection\nasync function resilientCacheOperation(key: string) {\n  try {\n    // Try cache first\n    let result = await cache.get(key);\n    \n    if (result === null) {\n      // Cache miss or circuit breaker open\n      result = await fallbackToDatabase(key);\n      \n      // Try to cache result (will be skipped if circuit breaker is open)\n      await cache.set(key, result, { ttl: 3600 });\n    }\n    \n    return result;\n  } catch (error) {\n    console.error('Cache operation failed, falling back to database:', error);\n    return await fallbackToDatabase(key);\n  }\n}\n\n// Monitor circuit breaker state\ncache.on('circuitBreakerOpen', ({ threshold, failures }) => {\n  console.warn(`Cache circuit breaker opened: ${failures} failures exceeded threshold ${threshold}`);\n  // Alert monitoring system...\n});\n\ncache.on('circuitBreakerClosed', () => {\n  console.info('Cache circuit breaker closed - operations resumed');\n});\n```\n\n## Health Checks\n\n```typescript\n// Implement health check endpoint\napp.get('/health/cache', async (req, res) => {\n  try {\n    const health = await cache.healthCheck();\n    const stats = cache.getStats();\n    \n    const response = {\n      status: health.healthy ? 'healthy' : 'unhealthy',\n      latency: health.latency,\n      errors: health.errors,\n      statistics: {\n        hitRate: stats.overall.hitRate,\n        l1KeyCount: stats.l1.keyCount,\n        l2KeyCount: stats.l2.keyCount,\n        memoryUsage: stats.l1.memoryUsage\n      },\n      timestamp: new Date().toISOString()\n    };\n    \n    res.status(health.healthy ? 200 : 503).json(response);\n  } catch (error) {\n    res.status(503).json({\n      status: 'error',\n      error: error.message,\n      timestamp: new Date().toISOString()\n    });\n  }\n});\n```\n\n## Configuration Examples\n\n```typescript\nimport { CacheConfigFactory, EnhancedCacheManager } from '@fineprintai/cache';\n\n// High-performance configuration for hot data\nconst highPerfCache = new EnhancedCacheManager(\n  CacheConfigFactory.createHighPerformance()\n);\n\n// Memory-optimized configuration for resource-constrained environments\nconst memoryOptimizedCache = new EnhancedCacheManager(\n  CacheConfigFactory.createMemoryOptimized()\n);\n\n// Custom configuration\nconst customConfig = CacheConfigFactory.merge(\n  CacheConfigFactory.createDefault(),\n  {\n    l1: {\n      maxSize: 50000,\n      maxMemory: 256 * 1024 * 1024 // 256MB\n    },\n    l2: {\n      compression: {\n        enabled: true,\n        algorithm: 'gzip',\n        threshold: 2048, // 2KB\n        level: 9 // Maximum compression\n      }\n    },\n    monitoring: {\n      slowLogThreshold: 50, // 50ms\n      alertThresholds: {\n        hitRateMin: 0.9, // 90%\n        errorRateMax: 0.01, // 1%\n        latencyMax: 100 // 100ms\n      }\n    }\n  }\n);\n\nconst customCache = new EnhancedCacheManager(customConfig);\n```\n\n## Performance Optimization Tips\n\n```typescript\n// 1. Use batch operations for multiple keys\nconst keys = ['user:1', 'user:2', 'user:3'];\nconst results = await cache.mget(keys); // Better than 3 individual gets\n\n// 2. Use appropriate TTLs\nawait cache.set('static:config', config, { ttl: 86400 }); // 24 hours for static data\nawait cache.set('user:session', session, { ttl: 1800 }); // 30 minutes for sessions\n\n// 3. Use tags for efficient invalidation\nawait cache.set('user:profile:123', profile, {\n  tags: ['user:123', 'profiles'],\n  ttl: 3600\n});\n\n// 4. Enable refresh-ahead for frequently accessed data\nawait cache.set('popular:data', data, {\n  ttl: 3600,\n  refreshAhead: true,\n  refreshThreshold: 20\n});\n\n// 5. Use compression for large values\nawait cache.set('large:document', document, {\n  compress: true,\n  ttl: 7200\n});\n\n// 6. Monitor and optimize based on metrics\nsetInterval(async () => {\n  const stats = cache.getStats();\n  if (stats.overall.hitRate < 0.8) {\n    console.warn('Low hit rate detected:', stats.overall.hitRate);\n    // Consider adjusting TTLs or warming strategy\n  }\n}, 300000); // Every 5 minutes\n```\n\nThese examples demonstrate the full capabilities of the enhanced cache system. The cache is designed to be production-ready with comprehensive error handling, monitoring, and performance optimization features.