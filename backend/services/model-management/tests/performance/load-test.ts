/**
 * Performance Load Testing Suite
 */

import { describe, it, expect, beforeAll, afterAll } from 'vitest';
import axios from 'axios';
import { performance } from 'perf_hooks';
import pino from 'pino';

const logger = pino({ name: 'load-test' });

interface LoadTestConfig {
  baseUrl: string;
  concurrency: number;
  duration: number; // seconds
  rampUpTime: number; // seconds
  scenarios: LoadTestScenario[];
}

interface LoadTestScenario {
  name: string;
  weight: number; // percentage
  endpoint: string;
  method: 'GET' | 'POST' | 'PUT' | 'DELETE';
  payload?: any;
  headers?: Record<string, string>;
  targetResponseTime: number; // ms
  targetSuccessRate: number; // percentage
}

interface LoadTestResults {
  scenario: string;
  totalRequests: number;
  successfulRequests: number;
  failedRequests: number;
  avgResponseTime: number;
  p50ResponseTime: number;
  p95ResponseTime: number;
  p99ResponseTime: number;
  minResponseTime: number;
  maxResponseTime: number;
  requestsPerSecond: number;
  errorRate: number;
  throughput: number;
  errors: Map<string, number>;
}

interface BenchmarkResult {
  name: string;
  operations: number;
  duration: number;
  opsPerSecond: number;
  avgDuration: number;
  minDuration: number;
  maxDuration: number;
}

export class LoadTester {
  private config: LoadTestConfig;
  private results: Map<string, LoadTestResults> = new Map();
  private active: boolean = false;

  constructor(config: LoadTestConfig) {
    this.config = config;
  }

  /**
   * Run load test
   */
  async runLoadTest(): Promise<Map<string, LoadTestResults>> {
    logger.info({ config: this.config }, 'Starting load test');
    
    this.active = true;
    const startTime = Date.now();
    const workers: Promise<void>[] = [];
    
    // Ramp up
    const rampUpInterval = this.config.rampUpTime * 1000 / this.config.concurrency;
    
    for (let i = 0; i < this.config.concurrency; i++) {
      await new Promise(resolve => setTimeout(resolve, rampUpInterval));
      workers.push(this.runWorker(i));
    }
    
    // Wait for duration
    setTimeout(() => {
      this.active = false;
    }, this.config.duration * 1000);
    
    // Wait for all workers to complete
    await Promise.all(workers);
    
    const totalDuration = (Date.now() - startTime) / 1000;
    
    // Calculate final results
    this.calculateFinalResults(totalDuration);
    
    logger.info({ results: Array.from(this.results.values()) }, 'Load test completed');
    
    return this.results;
  }

  /**
   * Run single worker
   */
  private async runWorker(workerId: number): Promise<void> {
    const workerResults: Map<string, any[]> = new Map();
    
    while (this.active) {
      // Select scenario based on weight
      const scenario = this.selectScenario();
      
      // Execute request
      const result = await this.executeRequest(scenario);
      
      // Store result
      const scenarioResults = workerResults.get(scenario.name) || [];
      scenarioResults.push(result);
      workerResults.set(scenario.name, scenarioResults);
      
      // Small delay to prevent overwhelming
      await new Promise(resolve => setTimeout(resolve, 10));
    }
    
    // Merge worker results
    this.mergeWorkerResults(workerResults);
  }

  /**
   * Select scenario based on weights
   */
  private selectScenario(): LoadTestScenario {
    const random = Math.random() * 100;
    let cumulative = 0;
    
    for (const scenario of this.config.scenarios) {
      cumulative += scenario.weight;
      if (random <= cumulative) {
        return scenario;
      }
    }
    
    return this.config.scenarios[0];
  }

  /**
   * Execute single request
   */
  private async executeRequest(scenario: LoadTestScenario): Promise<any> {
    const startTime = performance.now();
    let success = false;
    let error: string | null = null;
    
    try {
      const response = await axios({
        method: scenario.method,
        url: `${this.config.baseUrl}${scenario.endpoint}`,
        data: scenario.payload,
        headers: scenario.headers,
        timeout: 30000,
        validateStatus: (status) => status < 500
      });
      
      success = response.status < 400;
      if (!success) {
        error = `HTTP ${response.status}`;
      }
    } catch (err: any) {
      success = false;
      error = err.code || err.message;
    }
    
    const duration = performance.now() - startTime;
    
    return {
      scenario: scenario.name,
      success,
      duration,
      error,
      timestamp: Date.now()
    };
  }

  /**
   * Merge worker results
   */
  private mergeWorkerResults(workerResults: Map<string, any[]>): void {
    for (const [scenario, results] of workerResults) {
      const existing = this.results.get(scenario) || this.initializeResults(scenario);
      
      for (const result of results) {
        existing.totalRequests++;
        if (result.success) {
          existing.successfulRequests++;
        } else {
          existing.failedRequests++;
          const errorCount = existing.errors.get(result.error) || 0;
          existing.errors.set(result.error, errorCount + 1);
        }
      }
      
      this.results.set(scenario, existing);
    }
  }

  /**
   * Calculate final results
   */
  private calculateFinalResults(duration: number): void {
    for (const [scenario, results] of this.results) {
      // Get all response times
      const responseTimes: number[] = [];
      // Note: In a real implementation, we'd store individual response times
      
      // Calculate metrics
      results.errorRate = results.failedRequests / results.totalRequests * 100;
      results.requestsPerSecond = results.totalRequests / duration;
      results.throughput = results.successfulRequests / duration;
      
      // Update results
      this.results.set(scenario, results);
    }
  }

  /**
   * Initialize results for scenario
   */
  private initializeResults(scenario: string): LoadTestResults {
    return {
      scenario,
      totalRequests: 0,
      successfulRequests: 0,
      failedRequests: 0,
      avgResponseTime: 0,
      p50ResponseTime: 0,
      p95ResponseTime: 0,
      p99ResponseTime: 0,
      minResponseTime: Number.MAX_VALUE,
      maxResponseTime: 0,
      requestsPerSecond: 0,
      errorRate: 0,
      throughput: 0,
      errors: new Map()
    };
  }
}

/**
 * Cache Performance Benchmark
 */
export class CacheBenchmark {
  private results: BenchmarkResult[] = [];

  /**
   * Run cache benchmark
   */
  async runBenchmark(): Promise<BenchmarkResult[]> {
    logger.info('Starting cache benchmark');
    
    // Benchmark cache operations
    await this.benchmarkCacheGet();
    await this.benchmarkCacheSet();
    await this.benchmarkSemanticSearch();
    await this.benchmarkEviction();
    
    logger.info({ results: this.results }, 'Cache benchmark completed');
    
    return this.results;
  }

  /**
   * Benchmark cache get operations
   */
  private async benchmarkCacheGet(): Promise<void> {
    const operations = 10000;
    const durations: number[] = [];
    
    for (let i = 0; i < operations; i++) {
      const startTime = performance.now();
      
      // Simulate cache get
      await this.simulateCacheGet(`key-${i % 1000}`);
      
      durations.push(performance.now() - startTime);
    }
    
    this.results.push(this.calculateBenchmarkResult('Cache Get', operations, durations));
  }

  /**
   * Benchmark cache set operations
   */
  private async benchmarkCacheSet(): Promise<void> {
    const operations = 5000;
    const durations: number[] = [];
    
    for (let i = 0; i < operations; i++) {
      const startTime = performance.now();
      
      // Simulate cache set
      await this.simulateCacheSet(`key-${i}`, { data: 'test' });
      
      durations.push(performance.now() - startTime);
    }
    
    this.results.push(this.calculateBenchmarkResult('Cache Set', operations, durations));
  }

  /**
   * Benchmark semantic search
   */
  private async benchmarkSemanticSearch(): Promise<void> {
    const operations = 100;
    const durations: number[] = [];
    
    for (let i = 0; i < operations; i++) {
      const startTime = performance.now();
      
      // Simulate semantic search
      await this.simulateSemanticSearch('test query');
      
      durations.push(performance.now() - startTime);
    }
    
    this.results.push(this.calculateBenchmarkResult('Semantic Search', operations, durations));
  }

  /**
   * Benchmark cache eviction
   */
  private async benchmarkEviction(): Promise<void> {
    const operations = 1000;
    const durations: number[] = [];
    
    for (let i = 0; i < operations; i++) {
      const startTime = performance.now();
      
      // Simulate eviction
      await this.simulateEviction();
      
      durations.push(performance.now() - startTime);
    }
    
    this.results.push(this.calculateBenchmarkResult('Cache Eviction', operations, durations));
  }

  /**
   * Calculate benchmark results
   */
  private calculateBenchmarkResult(
    name: string,
    operations: number,
    durations: number[]
  ): BenchmarkResult {
    const totalDuration = durations.reduce((sum, d) => sum + d, 0);
    
    return {
      name,
      operations,
      duration: totalDuration,
      opsPerSecond: operations / (totalDuration / 1000),
      avgDuration: totalDuration / operations,
      minDuration: Math.min(...durations),
      maxDuration: Math.max(...durations)
    };
  }

  // Simulation methods
  private async simulateCacheGet(key: string): Promise<any> {
    // Simulate cache get latency
    await new Promise(resolve => setTimeout(resolve, Math.random() * 2));
    return { key, value: 'cached' };
  }

  private async simulateCacheSet(key: string, value: any): Promise<void> {
    // Simulate cache set latency
    await new Promise(resolve => setTimeout(resolve, Math.random() * 5));
  }

  private async simulateSemanticSearch(query: string): Promise<any[]> {
    // Simulate semantic search latency
    await new Promise(resolve => setTimeout(resolve, Math.random() * 50));
    return [];
  }

  private async simulateEviction(): Promise<void> {
    // Simulate eviction latency
    await new Promise(resolve => setTimeout(resolve, Math.random() * 10));
  }
}

/**
 * Model Performance Benchmark
 */
export class ModelBenchmark {
  private results: Map<string, BenchmarkResult> = new Map();

  /**
   * Run model benchmark
   */
  async runBenchmark(): Promise<Map<string, BenchmarkResult>> {
    logger.info('Starting model benchmark');
    
    // Benchmark different models
    await this.benchmarkModel('llama-model', 81000); // 81s avg
    await this.benchmarkModel('qwen-model', 937000); // 937s avg
    await this.benchmarkModel('gpt-oss-model', 465000); // 465s avg
    
    logger.info({ results: Array.from(this.results.values()) }, 'Model benchmark completed');
    
    return this.results;
  }

  /**
   * Benchmark individual model
   */
  private async benchmarkModel(modelId: string, avgResponseTime: number): Promise<void> {
    const operations = 10;
    const durations: number[] = [];
    
    for (let i = 0; i < operations; i++) {
      const startTime = performance.now();
      
      // Simulate model processing
      await this.simulateModelProcessing(avgResponseTime);
      
      durations.push(performance.now() - startTime);
    }
    
    const totalDuration = durations.reduce((sum, d) => sum + d, 0);
    
    this.results.set(modelId, {
      name: modelId,
      operations,
      duration: totalDuration,
      opsPerSecond: operations / (totalDuration / 1000),
      avgDuration: totalDuration / operations,
      minDuration: Math.min(...durations),
      maxDuration: Math.max(...durations)
    });
  }

  /**
   * Simulate model processing
   */
  private async simulateModelProcessing(avgTime: number): Promise<void> {
    // Add some variance (Â±20%)
    const variance = avgTime * 0.2;
    const actualTime = avgTime + (Math.random() - 0.5) * variance;
    
    // Simulate processing time (scaled down for testing)
    await new Promise(resolve => setTimeout(resolve, actualTime / 1000));
  }
}

// Test suite
describe('Performance Tests', () => {
  describe('Load Tests', () => {
    it('should handle concurrent requests', async () => {
      const config: LoadTestConfig = {
        baseUrl: 'http://localhost:3010',
        concurrency: 10,
        duration: 10,
        rampUpTime: 2,
        scenarios: [
          {
            name: 'Document Analysis',
            weight: 70,
            endpoint: '/api/v1/analyze',
            method: 'POST',
            payload: { document: 'test document' },
            targetResponseTime: 5000,
            targetSuccessRate: 95
          },
          {
            name: 'Cache Lookup',
            weight: 30,
            endpoint: '/api/v1/cache/lookup',
            method: 'GET',
            targetResponseTime: 100,
            targetSuccessRate: 99
          }
        ]
      };
      
      const tester = new LoadTester(config);
      const results = await tester.runLoadTest();
      
      // Verify results
      for (const [scenario, result] of results) {
        const scenarioConfig = config.scenarios.find(s => s.name === scenario);
        
        expect(result.totalRequests).toBeGreaterThan(0);
        expect(result.errorRate).toBeLessThan(100 - scenarioConfig!.targetSuccessRate);
        
        logger.info({
          scenario,
          requests: result.totalRequests,
          errorRate: result.errorRate,
          rps: result.requestsPerSecond
        }, 'Load test scenario results');
      }
    }, 30000); // 30 second timeout
  });
  
  describe('Cache Benchmarks', () => {
    it('should benchmark cache operations', async () => {
      const benchmark = new CacheBenchmark();
      const results = await benchmark.runBenchmark();
      
      expect(results).toHaveLength(4);
      
      for (const result of results) {
        expect(result.operations).toBeGreaterThan(0);
        expect(result.opsPerSecond).toBeGreaterThan(0);
        
        logger.info({
          operation: result.name,
          opsPerSecond: result.opsPerSecond,
          avgDuration: result.avgDuration
        }, 'Cache benchmark results');
      }
    });
  });
  
  describe('Model Benchmarks', () => {
    it('should benchmark model performance', async () => {
      const benchmark = new ModelBenchmark();
      const results = await benchmark.runBenchmark();
      
      expect(results.size).toBe(3);
      
      // Verify Llama is fastest
      const llama = results.get('llama-model');
      const qwen = results.get('qwen-model');
      const gptOss = results.get('gpt-oss-model');
      
      expect(llama!.avgDuration).toBeLessThan(qwen!.avgDuration);
      expect(llama!.avgDuration).toBeLessThan(gptOss!.avgDuration);
      
      for (const [modelId, result] of results) {
        logger.info({
          model: modelId,
          avgDuration: result.avgDuration,
          opsPerSecond: result.opsPerSecond
        }, 'Model benchmark results');
      }
    });
  });
  
  describe('Latency Benchmarks', () => {
    it('should measure P95 latency', async () => {
      const latencies: number[] = [];
      
      // Simulate 1000 requests
      for (let i = 0; i < 1000; i++) {
        const startTime = performance.now();
        
        // Simulate varying latency
        await new Promise(resolve => 
          setTimeout(resolve, Math.random() * 100)
        );
        
        latencies.push(performance.now() - startTime);
      }
      
      // Calculate percentiles
      latencies.sort((a, b) => a - b);
      const p50 = latencies[Math.floor(latencies.length * 0.5)];
      const p95 = latencies[Math.floor(latencies.length * 0.95)];
      const p99 = latencies[Math.floor(latencies.length * 0.99)];
      
      expect(p95).toBeLessThan(5000); // Target <5s for cached
      
      logger.info({
        p50,
        p95,
        p99
      }, 'Latency percentiles');
    });
  });
});

/**
 * Stress test runner
 */
export async function runStressTest(): Promise<void> {
  logger.info('Starting stress test');
  
  const config: LoadTestConfig = {
    baseUrl: process.env.API_URL || 'http://localhost:3010',
    concurrency: 100,
    duration: 300, // 5 minutes
    rampUpTime: 30,
    scenarios: [
      {
        name: 'Heavy Load',
        weight: 100,
        endpoint: '/api/v1/analyze',
        method: 'POST',
        payload: { document: 'large document '.repeat(1000) },
        targetResponseTime: 10000,
        targetSuccessRate: 90
      }
    ]
  };
  
  const tester = new LoadTester(config);
  const results = await tester.runLoadTest();
  
  logger.info({ results: Array.from(results.values()) }, 'Stress test completed');
}